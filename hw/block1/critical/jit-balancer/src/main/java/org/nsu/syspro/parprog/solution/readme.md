
## Дизайн Адаптивного компилятора

Ключевой паттерн дизайна адаптивного компилятора - это лок на данных. 
Конечно, лок, он и в Африке лок, но это способ думать о `mutal exclusion`.

Сама постановка задачи будто бы располагает к этому - существует множество
методов, каждый из которых может быть в разных состояниях. Было бы круто
'лочить' метод и как-то переводить его из одного состояния в другое.

### Как это реализовано?
#### Единица компиляции

Основная сущность решения - `CompilationUnit`,
инкапуслирует всю информацию о методе внутри
виртуальной машины. В том числе его уникальное
`methodID`, текущий уровень компиляции `JitLevel`,
горячесть и _состояние_  метода. Блокировка на `unit`'е 
осуществляется при помощи `ReentrantReadWriteLock`'а.

Каждый `CompilationUnit`
представляет собой state-machine. Полное состояние метода - это пара из 
`State = CREATED | ON_COMPILATION | COMPILED` и 
`JitLevel = INTERPRETED | L1 | L2`. Первая координата отражает
текущее состояние метода внутри VM, а вторая его уровень оптимизации его
кода в данном состоянии.

Машина содержит следующие переходы:

- `(CREATED, INTERPRETED) -> (ON_COMPILATION, INTERPRETED)`
- `(COMPILED, L1) -> (ON_COMPILATION, L1)`
- `(ON_COMPILATION, INTERPRETED) -> (COMPILED, L1)`
- `(ON_COMPILATION, L1) -> (COMPILED, L2)`

Других переходов нет. В реализации каждый из переходов происходит
атомарно при помощи `writeLock`'а.

Переходы `(ON_COMPILATION, _) -> (COMPILED, _.next)` осуществляются
асинхронно по отношению к пользовательским потокам VM.

Горячесть метода также обновляется атомарно. Это не очень производительно,
зато безопасно. Также при каждом изменении горячести может быть совершен
переход в состояние `ON_COMPILATION`.

Можно заметить, что вторая координата
монотонно неубывает в ходе работы машины.

После достижения наивысшего уровня оптимизации кода
прогресса в состояниях машины быть не может.

Важное свойство которое бы хотелось иметь для `CompilationUnit`'ов - 
> Каждому `MethodID` соответствует не более одного instance `CompilationUnit`'а

Это свойство гарантируется при помощи
следующей важной части решения - `Balancer`'а

---
#### Balancer

Такое название чересчур пафосное для класса-прослойки между `unit`'ами и
пользовательскими потоками, но как назвать его по-другому я так и не придумал.

Этот класс содержит в себе `ConcurrentHashMap`, которая является
глобальным кэшем. При помощи её достигается свойство названное выше.

В глобальный кэш добавляются _все_ методы горячесть которых когда-либо
инкрементировалась. Это чертовски неэффективно по памяти и имеет большие
издержки на синхронизацию,
возможный метод решения проблемы будет предложен в 
[вокранаундах](#Work-around).

---

#### Пользовательские потоки

В пользовательских потоках тоже много кэшей, а именно кэш 
под локальную горячесть и кэш скомпилированных методов.
Такое обилие кэшей необходимо для поддержания constraint'ов 
hard уровня задачи

## Constraints

### Easy

Большая часть условий практически бесплатные, рассмотрим только самые
интересные из них.

`Per-thread-monotonicity` гарантируется при помощи свойства неубывания
уровня компиляции в машине состояний метода и механизма синхронизации
локальных и глобальных кэшей.

`Eventual-per-thread-progress-1` гарантируется при помощи метода 
`waitCompilation(MethodID, JitLevel)`, который подписывает текущий
пользовательский поток на ожидание компиляции необходимого уровня.
При этом дополнительный триггер компиляции не требуется - 
синхронизация кэшей происходит каждый вызов метода
`executeMethod` и исполняемый метод будет переведён в состояние `ON_COMPILATION`
прежде чем любой пользовательский поток начнет ждать завершения компиляции.
Помимо словесного объяснения имеются и ассерты, а также проверка 
необходимых констант в классе `Tuner`.

`Weak-global-caching` гарантируется при помощи синхронизации глобальных 
и локальных кэшей. После того как метод будет скомпилирован первый поток
дошедший до точки синхронизации получит скомпилированную версию и сохранит 
её в локальном кэше. Таким образом гарантируется более сильное утверждение
> После того как метод скомпилирован пользовательский поток может
> интерпретировать этот метод не более одного раза.

Возможно это хороший поинт, чтобы ослабить издержки на синхронизацию, но
тогда придется усложнить механизм планирования компиляции и подсчета горячести.

### Medium

`Heavy-compilation-offloading` гарантируется за счет того, что
переходы `(ON_COMPILATION, _) -> (COMPILED, _.next)` осуществляются
асинхронно по отношению к пользовательским потокам.

`Eventual-per-thread-progress-2` такой же механизм как и в предыдущем уровне

### Hard

`Thread-bound-compilation` гарантируется частью кода, которой
я абсолютно не горжусь, но ничего лучше я не придумал. 
`Executors.newFixedThreadPool(workersBound)`, инициализируется с необходимым
количеством воркеров.

`CPU-bound-compilation` докажем, что это ограничение также выполнено.
Каждый `MethodID` соответствует единственному `CompilationUnit`.
Реализацией машины состояний гарантируется то что каждый юнит находится
в состоянии `ON_COMPILATION` атомарно тогда и только тогда когда
его компиляция запланирована. Любая запланированная компиляция завершается,
это свойство предоставлено `ExecutorService`.
Из переходов state-machine видно, что каждый юнит не может быть в состоянии
`ON_COMPILATION` более двух раз. Что и требовалось доказать.
Таким образом гарантируется даже более строгое утверждение
> Каждый метод компилируется не более двух раз.
> Один и тот же компилятор не может быть использован дважды для компиляции
> одного и того же метода.

`Weak-worst-case-latency` из-за ограничений `Limited-Threads` и `Limited-Methods`
обращение к локальным мапам работает за `O(1)`. Между точкой входа в метод
`executeMethod` пользовательским потоком и завершением исполнения или
интерпретации используются только локальные кэши, вся синхронизация происходит
позже. Естественно это очень неэффективно по памяти и имеет большие издержки
синхронизации.

## Work-around

Наверное лучшая идея, что у меня есть это изобрести threshold локальной
горячести до достижения которого метод не виден глобальным кэшам. Это 
позволит снизить размеры глобальных кэшей. Но часть сказанного выше
опирается на то что глобальный кэш обновляется каждый вызов `executeMethod`.
Но кажется что такой механизм, если его аккуратно реализовать не должен
нарушить какие-либо из описанных выше свойств.

Также есть возможности для улучшения механизма подсчета
глобальной горячести методов при помощи `LongAdder`'ов. Проблема в том, 
что извлечение суммы из них происходит неатомарно и полученная горячесть
может отставать от действительной. Опять же это не выглядит как большая проблема
учитывая то, что кэши горячести синхронизируются только в одну сторону. 
Но опять же это нужно обдумать ещё раз, аккуратно реализовать и покрыть ассертами.

Возможно ещё один хороший поинт для оптимизации следующее утверждение
> После достижения максимального уровня оптимизации юнит не прогрессирует.

Нужно как-то консистентно это проверить и больше не инкрементировать 
hotness на этом юните. Потребность в локе на запись в таком случае пропадает.

## Summary

Полученный дизайн прост в реализации, допускает хорошее покрытие ассертами
его свойства доказуемы, лок на данных и использование concurrent хэш таблицы
обеспечивает масштабируемость. Так как все блокирующие 
операции сосредоточены в одном месте и привязаны к изменению состояний 
допустить гонку достаточно сложно (но возможно у меня получилось, кто знает).

(ух прям такой менеджерский абзац)

Из недостатков - низкая производительность из-за больших издержек на
синхронизацию, высокое потребление памяти.
